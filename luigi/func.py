#This file contains most functions used in the project

# Web
import requests as rq
import requests

# Data analysis
import numpy as np
import pandas as pd
import json
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
import random as rand
from scipy import stats

# Convenience
from collections import Counter, defaultdict
import pickle
sns.set(style='darkgrid', palette='muted')

LOGIN_INFO = '../leiden_login_info/auth_info_main.json'
#LOGIN_INFO = '../leiden_login_info/auth_info.json'
#BASE_URI = "http://178.63.49.197:8080/spine-ws/"
BASE_URI = "https://euretos-brain.com/spine-ws"

login_request = requests.post(BASE_URI + "/login/authenticate", 
                              json=json.load(open(LOGIN_INFO)))
headers = {'x-token': login_request.json()['token']}

class SpecialCounter(Counter):
    ''' Counter, which can be divided by numeric. '''
    def __truediv__(self, other):
        new = SpecialCounter(self)
        for key in new.keys():
            new[key] /= other
        return new
    
def partial_second(f, second):
    ''' Helper function for reducing second 
    argument. '''
    def f_part(first):
        return f(first, second)
    return f_part

def average(lst):
    return sum(lst) / len(lst)

def return_disease_ids(row):
    '''Returns Euretos disease IDs when applied to a table 
    with column containing disease names'''
    
    disease_request = requests.post(BASE_URI + "/external/concepts/search",
                                json={
                                    "additionalFields": [],
                                    "queryString": "term:'%s' AND semanticcategory:'Disorders'" % (row['Disease']),
                                    "searchType": "TOKEN"
                                },
                                headers=headers)
    disease_ids = [disease['id'] for disease in disease_request.json()['content']]
    return disease_ids


def return_drug_ids(row):
    '''Returns Euretos drug IDs when applied to a table with column 
    containing Drugbank IDs'''

    drug_request = requests.post(BASE_URI + "/external/concepts/search",
                             json={
                                 "additionalFields": [],
                                 "queryString": "term:'%s'" % (row['Drugbank ID']),
                                 "semanticcategory": "Drug",
                                 "searchType": "TOKEN",
                                 "knowledgebase": "drugbank"
                             },
                             headers=headers)
    drug_ids = [drugs["id"] for drugs in drug_request.json()["content"]]
    return drug_ids


def find_direct_relations(row):
    '''Returns information (jsons) on direct relations for all 
    combinations of ids of drugs and diseases
    for a pair of concepts in the initial table'''
    
    json = {
        "leftInputs": list(map(str, row['drug_ids'])),
        "rightInputs": list(map(str, row['disease_ids'])),
        "additionalFields": ["directionalTriples"]
    }
    direct_relation_request = requests.post(BASE_URI + "/external/concept-to-concept/direct",
                                json=json,
                                headers=headers
                                )
    print("DOOOONE!")
    return direct_relation_request.json()


def pull_direct_relations_info(row):
    '''Retrieves and returns only important information from 
    jsons generated by direct_relation function.'''
    
    content = row['content']
    relations = [relations['relationships'] for relations in content]
    predicates = [item[0]['directionalTriples'] for item in relations]
    for i in range(len(predicates)):
        result = []
        for triple in predicates[i]:
            result.append((triple['predicate'], triple['tripleId']))
        predicates[i] = result
    scores = [relations['score'] for relations in content]
    return list(zip(predicates, scores))

def mark_if_direct(row):
    '''Changes direct relations column to binary.'''
    if row["direct_relations"]["totalElements"] != 0:
        return True
    else:
        return False

def get_indirect(row, table_number, row_number, filt=None):
    drug_ids = list(map(str, row['drug_ids']))
    disease_ids = list(map(str, row['disease_ids']))
    json_drug = {
      "additionalFields": ['directionalTriples', 'semanticCategory', 'semanticTypes'],
      "positiveFilters": [filt] if filt else [],
      "leftInputs": drug_ids,
      "relationshipWeightAlgorithm": "PWS",
      "rightInputs": disease_ids,
      "sort": "ASC"
    }
    print('*', end="")
    resp = rq.post(BASE_URI + "/external/concept-to-concept/indirect?size=10000", json=json_drug, headers=headers)
    filename = "./indirect_jsons/{}_{}.json".format(table_number, row_number)
    with open(filename, "w") as file_for_json:
        json.dump(resp.json(), file_for_json)
    return

def randomize_drugs_diseases(number, table):
    ''' Randomizes table certain number of times.'''
    random_table_counters = list()
    
    existing_set = set(zip(map(tuple, table["drug_ids"]), map(tuple, table["disease_ids"])))
    drug_ids_set = set(map(tuple, table["drug_ids"]))
    disease_ids_set = set(map(tuple, table["disease_ids"]))
    
    for num in range(number):
        rand.seed(0)
        random_table = pd.DataFrame(columns=['drug_ids', 'disease_ids'])
        sample_size = 0
        while sample_size < len(table):
            while True:
                drug_ids = rand.choice(list(drug_ids_set))
                disease_ids = rand.choice(list(disease_ids_set))
                drug_disease = (drug_ids, disease_ids)
                if not drug_disease in existing_set:
                    existing_set.add(drug_disease)
                    random_table.loc[sample_size] = [drug_ids, disease_ids]
                    sample_size += 1
                    break   
        random_table.to_hdf('./id_table_neg_%i.hdf' % num, 'w') # for safety
    return

def get_counters(number, protocol="semanticCategory"):
    '''Gets counters from existing tables and corresponding jsons.'''
    random_table_counters = list()
    for num in range(number):
        random_table = pd.read_hdf("./id_table_neg_%i.hdf" % num)
        random_table["direct"] = pd.read_hdf("./direct_short_{}".format(num))
        counter_list = get_sem_cat_counter_list(random_table, num, protocol)
        random_table_counters.append(counter_list)
        
    return random_table_counters

def sem_cat_gener(table, table_number, protocol="semanticCategory"):
    ''' Generator of semantic categories lists for 
    each drug-disease pair. protocol parameter can be "semanticCategory"
    (by default), "diversity", "semanticType", or "predicates"'''
#     rows = table["all_in_between"]
    for ind, row in table.iterrows():
        if protocol == "predicates":
            pred_list = list()
        else:
            sem_cat_list = list()
        drug_count = len(row["drug_ids"])
        disease_count = len(row["disease_ids"])
        json_filename = "./indirect_jsons/{}_{}.json".format(table_number, ind)
        
        with open(json_filename, "r") as json_file:
            all_in_between = json.load(json_file)
            content = all_in_between["content"]
            
        for entry in content:
            concept = entry["concepts"][1]
            
            if concept["id"] in row["drug_ids"] + row["disease_ids"]:
                print(concept["id"], row["drug_ids"] + row["disease_ids"])
                continue

            if protocol == "semanticType":
                sem_cat_list = sem_cat_list + concept["semanticTypes"]
            elif protocol == "semanticCategory" or protocol == "diversity":
                sem_cat_list.append(concept["semanticCategory"])
            elif protocol == "predicates":
                triples1 = entry["relationships"][0]["directionalTriples"]
                triples2 = entry["relationships"][1]["directionalTriples"]
                pred_list.append((tuple((triple["predicate"] 
                                         for triple in triples1)),
                                  tuple((triple["predicate"]
                                         for triple in triples2))))
        if protocol == "predicates":
            yield pred_list, drug_count, disease_count
        else:
            yield sem_cat_list, drug_count, disease_count
    #         if  length > 3:
    #             print(length)
    return


def get_type_mappings():
    type_table = pd.read_csv("./SemanticTypes_2013AA.txt", sep="|", header=None)
    mappings = {row[1]: row[2] for _, row in type_table.iterrows()}
    return mappings

def map_keys(mappings, dickt):
    new_dickt = SpecialCounter()
    for key in dickt.keys():
        if key in mappings.keys():
            key_mapping = mappings[key]
            new_dickt[key_mapping] = dickt[key]
        else:
            new_dickt[key] = dickt[key]
    return new_dickt

def get_sem_cat_counter_list(table, table_number, protocol="semanticCategory"):
    '''protocol parameter can be "semanticCategory" (by default), "diversity" or "semanticType" '''
    assert protocol in ["semanticType", "diversity", "semanticCategory", "predicates"]
    gener = sem_cat_gener(table, table_number, protocol)

    if protocol == "diversity":
        sem_cat_counter_list = [(SpecialCounter(sem_cat_list), drug_count * disease_count) 
                                for sem_cat_list, drug_count, disease_count 
                                in gener 
                                if drug_count * disease_count != 0]
    elif protocol == "semanticCategory":
        sem_cat_counter_list = [SpecialCounter(sem_cat_list) / (drug_count * disease_count) 
                                for sem_cat_list, drug_count, disease_count 
                                in gener]
    elif protocol == "semanticType":
        type_mappings = get_type_mappings()
        sem_cat_counter_list = [map_keys(type_mappings, SpecialCounter(sem_cat_list) / (drug_count * disease_count)) 
                                for sem_cat_list, drug_count, disease_count 
                                in gener]
    elif protocol == "predicates":
        big_pred_list = list()
        for pred_list, _, __ in gener:
            big_pred_list = big_pred_list + pred_list
        
        big_big_pred_list = list()
        for layer1, layer2 in big_pred_list:
            for pred1 in layer1:
                for pred2 in layer2:
                    big_big_pred_list.append("{}--->{}".format(pred1, pred2))
        return Counter(big_big_pred_list)
                    
    return sem_cat_counter_list

def get_hist(counter_list, cat=None, bins=None):
    if cat is not None:
        get_track_key = partial_second(Counter.__getitem__, cat)
        track = list(map(get_track_key, counter_list))
    else:
        track = counter_list        
    if bins is not None:
        hist = np.histogram(track, bins=bins)
    else:
        hist = np.histogram(track, bins=100)
    return hist

def plot_for_cat(cat, sem_cat_counter_list, color, bins, stds=None):
    ''' Function for plotting distribution by category. '''
    
    if stds:
        bin_width = bins[1] - bins[0]
        bins = (bins[:-1] + bins[1:]) / 2 # getting left edges for bar plot
        plt.bar(bins, sem_cat_counter_list, color=color, width=bin_width, yerr=stds, alpha=0.5)
    else:
        get_track_key = partial_second(Counter.__getitem__, cat)
        track = list(map(get_track_key, sem_cat_counter_list))
        min_lim = 0
        max_lim = np.percentile(track, 95)
        print(max_lim)
        plt.xlim(0, max_lim)
        plt.hist(track, color=color, bins=bins, alpha=0.5, range=(min_lim, max_lim))
        
    plt.xlabel("Normalized number of semantic category occurence between drug and disease")
    plt.ylabel("Drug-disease count")
    
def plot_both(cat, real_counter, randomized_counter_list):
    ''' Plots both random and nonrandom distributions 
    of concept counts within semantic category. ''' 
    bins = get_binsizes(cat, real_counter, randomized_counter_list)
    plt.figure()

    stds, avg_hist = get_stds_avghist(randomized_counter_list, bins, cat)
    
    plot_for_cat(cat, real_counter, "red", bins)
    red_patch = mpatches.Patch(color="red", alpha=0.5, label="positive")
    plot_for_cat(cat, avg_hist, "black", bins, stds)
    black_patch = mpatches.Patch(color="black", alpha=0.5, label="negative")
    plt.legend(handles=[red_patch, black_patch])
    plt.title(cat)
    plt.savefig("./new_pictures/{}.png".format(cat), format="png")

def get_stds_avghist(counter_list, bins, cat=None):
    ''' Gets standard deviations and average bar heights
    for list of distributions. '''
    
    hist_list = [get_hist(counter, cat, bins)[0] for counter in counter_list]
    stds = list(map(np.std, zip(*hist_list)))
    avghist = list(map(average, zip(*hist_list)))
    return stds, avghist

def get_binsizes(cat, real_counter, randomized_counter_list):
    summed_randomized_counter = list()
    scaled_real_counter = list()
    for counter in randomized_counter_list:
        scaled_real_counter += real_counter
        summed_randomized_counter += counter
    sum_hist = get_hist(scaled_real_counter + summed_randomized_counter, cat)
    bins = sum_hist[1]
    return bins

def plot_diversity(nonrandom_counter, random_counter_list):
    diversity_random_list_list = [[len(counter.keys()) / norm for counter, norm in random_counter] 
                           for random_counter in random_counter_list]
    diversity_nonrandom_list = [len(counter.keys()) / norm for counter, norm in nonrandom_counter]
    
    whole_diversity_random_list = list()
    for diversity_random_list in diversity_random_list_list:
        whole_diversity_random_list += diversity_random_list
    diversity_bins = len(set(whole_diversity_random_list + diversity_nonrandom_list)) // 3 # questionable
    
    stds, avg_hist = get_stds_avghist(counter_list=diversity_random_list_list, bins=diversity_bins)

    _, bins, __ = plt.hist(diversity_nonrandom_list, bins=diversity_bins, color="red", alpha=0.5)
    bin_width = bins[1] - bins[0]
    bins = (bins[:-1] + bins[1:]) / 2 # getting left edges for bar plot
    plt.bar(bins, avg_hist, color="black", width=bin_width, yerr=stds, alpha=0.5)
    
#     plt.title("Diversity")
    red_patch = mpatches.Patch(color="red", alpha=0.5, label="positive data")
    black_patch = mpatches.Patch(color="black", alpha=0.5, label="negative data")
    plt.legend(handles=[red_patch, black_patch])
    plt.xlabel("Normalised diversity of semantic categories between drug and disease")
    plt.ylabel("Count")

def test_if_the_same(random_counter, real_counter, cat):
    random_sample = [counter[cat] for counter in random_counter]
    real_sample = [counter[cat] for counter in real_counter]
    return stats.ks_2samp(random_sample, real_sample)
