{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from func import *\n",
    "from importlib import reload\n",
    "from scipy import stats\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x-token': 'ci5hLmt1ZHJpbkBnbWFpbC5jb21Nb24gQXVnIDI4IDE2OjA5OjI0IENFU1QgMjAxNzdiZDI2ZjNkLTg4MjktNGIzNS04Y2UwLTM1MDEwOGJhYzRlZg=='}\n"
     ]
    }
   ],
   "source": [
    "print(func.headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "func = reload(func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Load random and nonrandom samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "table = pd.read_hdf(\"./id_table.hdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "random_counters = get_counters(10, protocol=\"semanticType\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "random_counter = list()\n",
    "for counter_list in random_counters:\n",
    "    random_counter = random_counter + counter_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "real_counter = get_sem_cat_counter_list(table, \"real\", protocol=\"semanticType\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "real_counter_old = func.get_sem_cat_counter_list(table, \"real\", protocol=\"semanticType\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for counter1, counter2 in zip(real_counter, real_counter_old):\n",
    "    print(counter1, counter2, sep=\"\\n\", end=\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(len(random_counter), len(real_counter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Kolmogorov-Smirnov test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def test_if_the_same(random_counter, real_counter, cat):\n",
    "    random_sample = [counter[cat] for counter in random_counter]\n",
    "    real_sample = [counter[cat] for counter in real_counter]\n",
    "    return stats.ks_2samp(random_sample, real_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cats = set()\n",
    "for counter in real_counter + random_counter:\n",
    "    cats = cats | set(counter.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "differences = [(cat, test_if_the_same(random_counter, real_counter, cat)) for cat in cats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for dif in differences:\n",
    "    if dif[1].pvalue < 0.05:\n",
    "        print(dif[0], \"{0:.2E}\".format(dif[1].pvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "group_dataframe = pd.read_csv(\"./SemGroups_2013.txt\", sep=\"|\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "del group_dataframe[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "group_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dif_dataframe = pd.DataFrame()\n",
    "dif_dataframe[\"Semantic type(subcategory)\"] = pd.Series([dif[0] for dif in differences])\n",
    "dif_dataframe[\"P-value\"] = pd.Series([dif[1][1] for dif in differences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dif_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "new_one = pd.merge(dif_dataframe, group_dataframe, how=\"left\", left_on=\"Semantic type(subcategory)\", right_on=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "del new_one[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "new_one[\"Semantic category\"] = new_one[1]\n",
    "del(new_one[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "new_one = new_one.sort_values(by=\"P-value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Differentiate between directed and nondirected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_table = pd.read_hdf(\"./id_table.hdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n",
      "DOOOONE!\n"
     ]
    }
   ],
   "source": [
    "something = id_table.apply(find_direct_relations, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_table[\"direct_relations\"] = something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_table[\"direct_relations\"] = id_table.apply(func.mark_if_direct, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341\n"
     ]
    }
   ],
   "source": [
    "print(sum([1 if bol else 0 for bol in id_table[\"direct_relations\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modify_tables(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wordclouds for predicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_counter = func.get_sem_cat_counter_list(id_table, \"real\", protocol=\"predicates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wcloud = WordCloud(width=2000, height=1000, max_words=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generated = wcloud.generate_from_frequencies(pred_counter)\n",
    "neg_generated = wcloud.generate_from_frequencies(neg_pred_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set_style(style=\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize = (15, 8))\n",
    "plt.imshow(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize = (15, 8))\n",
    "plt.imshow(neg_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wcloud.generate_from_frequencies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_table = pd.read_hdf(\"./id_table_neg_0.hdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_pred_counter = func.get_sem_cat_counter_list(neg_table, 0, protocol=\"predicates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_pred_counter.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_keys = set()\n",
    "second_keys = set()\n",
    "for key in list(neg_pred_counter.keys()) + list(pred_counter.keys()):\n",
    "    first_key = key.split(\"--->\")[0]\n",
    "    second_key = key.split(\"--->\")[1]\n",
    "    first_keys.add(first_key)\n",
    "    second_keys.add(second_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(first_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class normDict(defaultdict):\n",
    "    \n",
    "    def normalize(self):\n",
    "        whole = 0\n",
    "        for value in self.values():\n",
    "            whole += value\n",
    "        for key in self.keys():\n",
    "            self[key] = self[key] / whole\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "def get_prob(counter):\n",
    "    prob_dict = defaultdict(lambda: normDict(int)) \n",
    "    for first_key in first_keys: \n",
    "        for second_key in second_keys:\n",
    "            for key in counter.keys():\n",
    "                if \"--->\".join([first_key, second_key]) == key:\n",
    "                    prob_dict[first_key][second_key] += 1\n",
    "    for key in prob_dict.keys():\n",
    "        prob_dict[key].normalize()\n",
    "    return prob_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prob_dict, neg_prob_dict = get_prob(pred_counter), get_prob(neg_pred_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for first in list(prob_dict.keys()) + list(neg_prob_dict.keys()):\n",
    "    print(first, dict(prob_dict[first]), dict(neg_prob_dict[first]), sep=\"\\n\", end=\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open(\"table_number.pkl\", \"wb\") as number_file:\n",
    "    pkl.dump(20, number_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
